import argparse
import json
import sys
import requests

# This script fetches published security advisories by iterating over all repos
# in the open-telemetry org. This approach is slower than using the org-level
# security advisories endpoint, but does not require elevated permissions that
# would also grant access to draft (unpublished) advisories.

parser = argparse.ArgumentParser()
parser.add_argument('output_file', help='Path to output JSON file')
args = parser.parse_args()

headers = {
    'Accept': 'application/vnd.github+json',
    'X-GitHub-Api-Version': '2022-11-28'
}

# Get all public repos in the open-telemetry org
repos = []
url = 'https://api.github.com/orgs/open-telemetry/repos?per_page=100&type=public'
while url:
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f'Failed to fetch repos: {response.status_code}')
        print(response.text)
        sys.exit(1)
    repos.extend(response.json())
    url = response.links.get('next', {}).get('url')

# Fetch published security advisories for each repo
advisories = []
for repo in repos:
    repo_name = repo['name']
    url = f'https://api.github.com/repos/open-telemetry/{repo_name}/security-advisories?state=published'
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f'Failed to fetch advisories for {repo_name}: {response.status_code}')
        print(response.text)
        sys.exit(1)
    repo_advisories = response.json()
    if repo_advisories:
        advisories.extend(repo_advisories)

# Extract fields and filter out test advisories
output = []
for item in advisories:
    summary = item.get('summary', '')
    if 'test only' in summary.lower():
        continue
    output.append({
        'ghsa_id': item.get('ghsa_id'),
        'cve_id': item.get('cve_id') or 'na',
        'html_url': item.get('html_url'),
        'summary': summary,
        'severity': item.get('severity'),
        'state': item.get('state'),
        'created_at': item.get('created_at') or 'na',
        'updated_at': item.get('updated_at') or 'na',
        'repo': item.get('html_url', '').split('/')[4] if item.get('html_url') else 'na'
    })

with open(args.output_file, 'w') as f:
    json.dump(output, f)
